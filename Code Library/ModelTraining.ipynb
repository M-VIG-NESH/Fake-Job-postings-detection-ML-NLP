{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas numpy matplotlib seaborn nltk emoji scikit-learn==1.3.2 imbalanced-learn==0.11.0\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words(\"english\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import html \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,ConfusionMatrixDisplay , classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ADASYN Upsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading \n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/clean-df/clean_df\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['fraudulent','text', 'token','Unnamed: 0'], axis=1)\n",
    "y=df['fraudulent']\n",
    "\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(X[\"clean_text\"])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text_vectorizer = CountVectorizer(stop_words='english', min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(X['clean_text'])\n",
    "count_text_vectors.shape\n",
    "import joblib\n",
    "joblib.dump(tfidf_text_vectorizer, \"tfidif_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "under_sample = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "\n",
    "X_tf, y_tf= under_sample.fit_resample(tfidf_text_vectors, y)\n",
    "\n",
    "X_bow, y_bow= under_sample.fit_resample(count_text_vectors, y)\n",
    "\n",
    "\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_tf,y_tf, test_size=0.20,random_state=0,stratify=y_tf)\n",
    "\n",
    "\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow,y_bow, test_size=0.20,random_state=0,stratify=y_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modeling \n",
    "\n",
    "## Logistic Regression tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C= 3,solver= 'liblinear',random_state = 42)\n",
    "logreg.fit(X_train_tf, y_train_tf)\n",
    "import joblib\n",
    "joblib.dump(logreg, \"fake_job_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "\n",
    "lr_predict = logreg.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, lr_predict))\n",
    "\n",
    "\n",
    "cm_lr =confusion_matrix(y_test_tf, lr_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_lr)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(y_test_tf, lr_predict))\n",
    "\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, lr_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, lr_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, lr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C= 3,solver= 'liblinear',random_state = 42)\n",
    "logreg.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predict = logreg.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, lr_predict))\n",
    "\n",
    "\n",
    "cm_lr =confusion_matrix(y_test_bow, lr_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_lr)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, lr_predict))\n",
    "\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, lr_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, lr_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, lr_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300,max_depth = 300, random_state = 2)\n",
    "rf.fit(X_train_tf, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_predict = rf.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, rf_predict))\n",
    "\n",
    "cm_rf =confusion_matrix(y_test_tf, rf_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Accuracy\", accuracy_score(y_test_tf, rf_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, rf_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, rf_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, rf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300,max_depth = 300, random_state = 2)\n",
    "rf.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_predict = rf.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, rf_predict))\n",
    "\n",
    "cm_rf =confusion_matrix(y_test_bow, rf_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, rf_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, rf_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, rf_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, rf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_tf, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predict = NB.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, nb_predict))\n",
    "\n",
    "cm_nb =confusion_matrix(y_test_tf, nb_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_nb)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_tf, nb_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, nb_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, nb_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, nb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predict = NB.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, nb_predict))\n",
    "\n",
    "cm_nb =confusion_matrix(y_test_bow, nb_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_nb)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, nb_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, nb_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, nb_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, nb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='adam', \n",
    "                    activation = 'relu',\n",
    "                   hidden_layer_sizes = (100,50,2), \n",
    "                    random_state=5,\n",
    "                    max_iter = 1000)  \n",
    "mlp.fit(X_train_tf,y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predict = mlp.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, mlp_predict))\n",
    "\n",
    "cm_mlp =confusion_matrix(y_test_tf, mlp_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_mlp)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_tf, mlp_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, mlp_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, mlp_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, mlp_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron BoW\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='adam', \n",
    "                    activation = 'relu',\n",
    "                   hidden_layer_sizes = (100,50,2), \n",
    "                    random_state=5,\n",
    "                    max_iter = 1000)  \n",
    "mlp.fit(X_train_bow,y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predict = mlp.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, mlp_predict))\n",
    "\n",
    "cm_mlp =confusion_matrix(y_test_bow, mlp_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_mlp)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, mlp_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, mlp_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, mlp_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, mlp_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=6,weights = 'uniform')\n",
    "\n",
    "knn.fit(X_train_tf,y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict = knn.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, knn_predict))\n",
    "\n",
    "cm_knn =confusion_matrix(y_test_tf, knn_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_knn)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_tf, knn_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, knn_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, knn_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, knn_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6,weights = 'uniform')\n",
    "knn.fit(X_train_bow,y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predict = knn.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, knn_predict))\n",
    "\n",
    "cm_knn =confusion_matrix(y_test_bow, knn_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_knn)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, knn_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, knn_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, knn_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, knn_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C= 2.0, kernel = 'linear',gamma = 'auto' )\n",
    "\n",
    "svc.fit(X_train_tf, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict = svc.predict(X_test_tf)\n",
    "\n",
    "print(classification_report(y_test_tf, svm_predict))\n",
    "\n",
    "cm_svm =confusion_matrix(y_test_tf, svm_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_tf, svm_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_tf, svm_predict))\n",
    "print(\"Precision\", precision_score(y_test_tf, svm_predict))\n",
    "print(\"Recall\", recall_score(y_test_tf, svm_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C= 2.0, kernel = 'linear',gamma = 'auto' )\n",
    "\n",
    "svc.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predict = svc.predict(X_test_bow)\n",
    "\n",
    "print(classification_report(y_test_bow, svm_predict))\n",
    "\n",
    "cm_svm =confusion_matrix(y_test_bow, svm_predict)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm_svm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test_bow, svm_predict))\n",
    "\n",
    "print(\"F1 Score\", f1_score(y_test_bow, svm_predict))\n",
    "print(\"Precision\", precision_score(y_test_bow, svm_predict))\n",
    "print(\"Recall\", recall_score(y_test_bow, svm_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC  Curve  of TF-IDF Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "plt.figure(0).clf()\n",
    "plt.title(\"AUC Curve of ADASYN Upsample Data with TF-IDF Vectorizer\")\n",
    "\n",
    "#fit logistic regression model and plot ROC curve\n",
    "lr = LogisticRegression(C= 3,solver= 'liblinear',random_state = 42)\n",
    "lr.fit(X_train_tf, y_train_tf)\n",
    "y_pred_lr = lr.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_lr)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_lr), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "#fit gradient boosted model and plot ROC curve\n",
    "svc = SVC(C= 2.0, kernel = 'linear',gamma = 'auto' ,probability=True )\n",
    "svc.fit(X_train_tf, y_train_tf)\n",
    "y_pred_svc = svc.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_svc)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_svc), 4)\n",
    "plt.plot(fpr,tpr,label=\"SVC, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "#fit gradient boosted model and plot ROC curve\n",
    "knn = KNeighborsClassifier(n_neighbors=6,weights = 'uniform')\n",
    "knn.fit(X_train_tf, y_train_tf)\n",
    "y_pred_knn = knn.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_knn)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_knn), 4)\n",
    "plt.plot(fpr,tpr,label=\"KNeighborsClassifier, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300,max_depth = 300, random_state = 2)\n",
    "rf.fit(X_train_tf, y_train_tf)\n",
    "y_pred_rf = rf.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_rf)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_rf), 4)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest\"+str(auc))\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', \n",
    "                    activation = 'relu',\n",
    "                   hidden_layer_sizes = (100,50,2), \n",
    "                    random_state=5,\n",
    "                    max_iter = 1000)   \n",
    "mlp.fit(X_train_tf,y_train_tf)\n",
    "y_pred_mlp = mlp.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_mlp)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_mlp), 4)\n",
    "plt.plot(fpr,tpr,label=\"mlp\"+str(auc))\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tf, y_train_tf)\n",
    "y_pred_nb = nb.predict_proba(X_test_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_tf, y_pred_nb)\n",
    "auc = round(metrics.roc_auc_score(y_test_tf, y_pred_nb), 4)\n",
    "plt.plot(fpr,tpr,label=\"Naive Bayes\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC of BoW Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "plt.figure(0).clf()\n",
    "\n",
    "plt.title(\"AUC Curve of ADASYN Upsample Data with BoW Vectorizer\")\n",
    "\n",
    "#fit logistic regression model and plot ROC curve\n",
    "lr = LogisticRegression(C= 3,solver= 'liblinear',random_state = 42)\n",
    "lr.fit(X_train_bow, y_train_bow)\n",
    "y_pred_lr = lr.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_lr)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_lr), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "\n",
    "#fit gradient boosted model and plot ROC curve\n",
    "svc = SVC(C= 2.0, kernel = 'linear',gamma = 'auto' ,probability=True )\n",
    "svc.fit(X_train_bow, y_train_bow)\n",
    "y_pred_svc = svc.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_svc)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_svc), 4)\n",
    "plt.plot(fpr,tpr,label=\"SVC, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "#fit gradient boosted model and plot ROC curve\n",
    "knn = KNeighborsClassifier(n_neighbors=6,weights = 'uniform')\n",
    "knn.fit(X_train_bow, y_train_bow)\n",
    "y_pred_knn = knn.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_knn)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_knn), 4)\n",
    "plt.plot(fpr,tpr,label=\"KNeighborsClassifier, AUC=\"+str(auc))\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 300,max_depth = 300, random_state = 2)\n",
    "rf.fit(X_train_bow, y_train_bow)\n",
    "y_pred_rf = rf.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_rf)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_rf), 4)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest\"+str(auc))\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', \n",
    "                    activation = 'relu',\n",
    "                   hidden_layer_sizes = (100,50,2), \n",
    "                    random_state=5,\n",
    "                    max_iter = 1000)   \n",
    "mlp.fit(X_train_bow,y_train_bow)\n",
    "y_pred_mlp = mlp.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_mlp)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_mlp), 4)\n",
    "plt.plot(fpr,tpr,label=\"mlp\"+str(auc))\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train_bow)\n",
    "y_pred_nb = nb.predict_proba(X_test_bow)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_bow, y_pred_nb)\n",
    "auc = round(metrics.roc_auc_score(y_test_bow, y_pred_nb), 4)\n",
    "plt.plot(fpr,tpr,label=\"Naive Bayes\"+str(auc))\n",
    "\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
