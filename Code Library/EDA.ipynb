{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pandas numpy matplotlib seaborn nltk emoji scikit-learn==1.3.2 imbalanced-learn==0.11.0 wordcloud\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words(\"english\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import html \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading data \n",
    "df = pd.read_csv(\"/kaggle/input/dataset/fake_job_postings.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will be exploring our data by looking at the various aspects such as checking null values, duplicates, class imbalance, data types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to checking null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information on Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sustituting null values with na \n",
    "df_na =df.fillna('na') \n",
    "\n",
    "real=df_na[df_na.fraudulent==0]\n",
    "fake=df_na[df_na.fraudulent==1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheching the rates of na \n",
    "na_rates=pd.DataFrame([col, len(real.loc[real[col]=='na'])/len(real[col]), len(fake.loc[fake[col]=='na'])/len(fake[col]) ] for col in df.columns)\n",
    "\n",
    "na_rates.columns=['column','real_na_rates','fake_na_rates']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-test on null values \n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "for col in df.columns:\n",
    "    counts=np.array([len(real.loc[real[col]=='na']), len(fake.loc[fake[col]=='na'])])\n",
    "    nobs=np.array([len(real[col]), len(fake[col])])\n",
    "    if (counts.sum() !=0) and (nobs.sum() !=0):\n",
    "        na_rates.loc[na_rates.column==col,'zstat'], na_rates.loc[na_rates.column==col,'p_value']=proportions_ztest(count=counts, nobs=nobs,  alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rates['significant_diff']=na_rates['p_value']<0.005\n",
    "na_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The Z-tests indicate that differences of na-rates among real and fake job-postings are mostly statistically significant, except in 'location', 'department', 'benefits' and 'function'. The difference is largest in company profile, where 68% of fake ads do not have a company profile, but only 16.1% of real ads omit company profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting duplicate value\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "\n",
    "No duplicates identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statististics of numeric data \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From describe() fuctution we can see our data has 4 numerical columns named as job_id, telecommuting, has_company_logo and has_questions.We can  remove these columns as they are of no use in text classification problems. We can see another numerical feature 'fraudulent' but here this columns will be used as our target variable in which the models will be trained and predicted.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Class Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see how many jobs posted are fraud and real.\n",
    "plt.title(\"\")\n",
    "sns.countplot(df.fraudulent)\n",
    "df.groupby('fraudulent').count()['title'].reset_index().sort_values(by='title',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling NAs with empty string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling na with empty space\n",
    "df.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Job posting by countries and Total fake job posting by countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining country name by splitting location\n",
    "def split(location):\n",
    "    l = location.split(',')\n",
    "    return l[0]\n",
    "\n",
    "df['country'] = df.location.apply(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = dict(df.country.value_counts()[:11])\n",
    "del country[' ']\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('No. of job postings country wise', size=20)\n",
    "plt.bar(country.keys(), country.values())\n",
    "plt.ylabel('No. of jobs', size=10)\n",
    "plt.xlabel('Countries', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of characters in description feature \n",
    "\n",
    "fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n",
    "length= df[df[\"fraudulent\"]==1]['description'].str.len()\n",
    "ax1.hist(length,bins = 20,color='orangered')\n",
    "ax1.set_title('Fake Post')\n",
    "length=df[df[\"fraudulent\"]==0]['description'].str.len()\n",
    "ax2.hist(length, bins = 20)\n",
    "ax2.set_title('Real Post')\n",
    "fig.suptitle('Characters in description')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap fpr correlation of numeeric features \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df.copy()\n",
    "for col in df_encoded.select_dtypes(include=['object']).columns:\n",
    "    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])\n",
    "\n",
    "corr = df_encoded.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting fake and real data \n",
    "fake=df[df.fraudulent==1]\n",
    "#fake\n",
    "real = df[df.fraudulent==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical plots to cheeck relationship of binary features with fradulent transaction \n",
    "sns.catplot(data=df,y='fraudulent', x='telecommuting', kind='bar')\n",
    "sns.catplot(data=df, y='fraudulent', x='has_company_logo', kind='bar')\n",
    "sns.catplot(data=df, y='fraudulent', x='has_questions', kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The following graphs of three binary features show that ads of jobs involving telecommuting, do not have company logo and screening questions are more likely to be fake. Among the three features, the absence of company logo is the most indicative, with 16% of ads without company logo to be fake, while only 2% of ads with company logo are fraudulent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barplot for visualization of data points in each countries for both fake jobs \n",
    "country = dict(fake.country.value_counts()[:11])\n",
    "del country[' ']\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('No. of fake job postings country wise', size=20)\n",
    "plt.bar(country.keys(), country.values())\n",
    "plt.ylabel('No. of fake jobs', size=10)\n",
    "plt.xlabel('Countries', size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barplot for visualization of data points in each countries for both real jobs \n",
    "\n",
    "country = dict(real.country.value_counts()[:11])\n",
    "del country[' ']\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('No. of real job postings country wise', size=20)\n",
    "plt.bar(country.keys(), country.values(), color ='orange')\n",
    "plt.ylabel('No. of real jobs', size=10)\n",
    "plt.xlabel('Countries', size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "It looks like United states has most job posting in the data compared to other countries and even the fake job posting are mostly in the United states and other countries has very less amount of fake job posting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fake job postings by title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barplot of job postings by title of job\n",
    "\n",
    "titles = dict(fake.department.value_counts()[:11])\n",
    "del titles[' ']\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('No. of fake job postings department wise', size=20)\n",
    "names = list(titles.keys())\n",
    "values = list(titles.values())\n",
    "\n",
    "plt.barh(range(len(titles)), values, tick_label=names)\n",
    "plt.ylabel('Titles of job', size=10)\n",
    "plt.xlabel('No of fake job', size=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in characters of description of fake jobs and real jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)= plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\n",
    "length= df[df[\"fraudulent\"]==1]['description'].str.len()\n",
    "ax1.hist(length,bins = 20,color='orangered')\n",
    "ax1.set_title('Fake Post')\n",
    "length=df[df[\"fraudulent\"]==0]['description'].str.len()\n",
    "ax2.hist(length, bins = 20)\n",
    "ax2.set_title('Real Post')\n",
    "fig.suptitle('Characters in description')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Merging seven text column which are significant on determining real and fakee jobs. The features “title”, “company profile”, “description”, “employment_type”, “required_experience” , “required education” and “industry” were combined into a single feature called “text” \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining significant text features \n",
    "df['text']=df.title+' '+df.company_profile+' '+df.description+' '+df.employment_type+' '+df.required_experience+' '+df.required_education+' '+df.industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting characters in text feature for each data points \n",
    "df['character_count'] = df['text'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency plot for distribution of words on text\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "df[df.fraudulent==0].character_count.plot(bins=35, kind='hist', color='blue', \n",
    "                                       label='Real', alpha=0.8)\n",
    "df[df.fraudulent==1].character_count.plot(kind='hist', color='red', \n",
    "                                       label='Fake', alpha=0.8)\n",
    "plt.legend()\n",
    "plt.title('Frequency of the Words in Text Information ',size=20)\n",
    "plt.xlabel(\"Character Count\",size=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution of charaters in description of the fake and real post are similar. Some fake post reach to 6000 to 8000 characters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting features relavant for text classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting necessary features\n",
    "features = ['text', 'fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making new data frame with relavant features \n",
    "df_new = df[features]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"text\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing HTML tags from the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the html tags from the data \n",
    "for i in df.index:\n",
    "    df_new.at[i, 'text'] = re.sub(r'https?://\\S+', '', df_new.at[i, 'text'])\n",
    "    \n",
    "\n",
    "#testing if the code worked    \n",
    "df_new[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Cleaning\n",
    "\n",
    "1) Removing HTML tags\n",
    "\n",
    "2) Removing punctuations\n",
    "\n",
    "3) Removing Stop words\n",
    "\n",
    "4) Removing Numerical values\n",
    "\n",
    "5) Case Normalization \n",
    "\n",
    "6) Lemmatization\n",
    "\n",
    "7) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation)\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# speeds up comparison\n",
    "\n",
    "def remove_punc(text):\n",
    "    text_nonpunc =\"\".join([char for char in text if char not in punctuation])\n",
    "    return text_nonpunc\n",
    "\n",
    "# Define Tokenization Function\n",
    "#To keep the emojis while tokenizing\n",
    "RE_TOKEN = re.compile(r\"\"\"\n",
    "                   ( [#]?[@\\w'’\\.\\-\\:]*\\w     # words, hashtags and email addresses\n",
    "                   | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
    "                   | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
    "                   )\n",
    "                  \"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "    \n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Define Stop Words Remove Function\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "#function for removing stop words \n",
    "def remove_stop(text, stop_words = sw) :\n",
    "     # modify this function to remove stopwords .split(' ')\n",
    "    return(\" \".join([word for word in text.split(' ') if word not in stop_words ]))\n",
    " \n",
    "#function for removing  punctuation\n",
    "\n",
    "def remove_punctuation(text, punct_set=punctuation) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "\n",
    "#function for lemmmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "#function for reeemoving numeric data \n",
    "\n",
    "def remove_number(text):\n",
    "    return (''.join([x for x in text if not x.isdigit()]))\n",
    "\n",
    "\n",
    "# Define pipeline of lowering, no punctuation, tokenization, and removal of stopwords\n",
    "pipeline1 = [str.lower,remove_stop,remove_punctuation,remove_number,lemmatize_words]\n",
    "\n",
    "\n",
    "def prepare(text, pipeline): \n",
    "    tokens = text\n",
    "    for transform in pipeline: tokens = transform(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Puctuations, Lower Casing and Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying cleaning pipeline to the text data\n",
    "df_new['clean_text'] = df_new['text'].apply(prepare, pipeline = pipeline1)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['clean_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying cleaning pipeline to the text data\n",
    "\n",
    "pipeline2= [tokenize]\n",
    "df_new['token'] = df_new['clean_text'].apply(prepare, pipeline = pipeline2)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for generating descriptive statistics \n",
    "\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \n",
    "    #filled na with whitespace to work with df and making sure it will\n",
    "    #not be counted on frequent words\n",
    "    tokens = [token for token in tokens if token not in ['', \" \"]]\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens =  len(tokens)\n",
    "    num_unique_tokens = len(set(tokens)) #len(np.unique(tokens))\n",
    "    lexical_diversity =  len(set(tokens)) / len(tokens) \n",
    "    num_characters =  sum([len(i) for i in tokens]) \n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        print(Counter(tokens).most_common(5))\n",
    "\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive Stats of fraudulent text\n",
    "fraud_df = df_new[df_new['fraudulent']== 1]\n",
    "token_fraud = []\n",
    "for i in fraud_df['token']:\n",
    "    token_fraud.extend(i)    \n",
    "print('Descriptive Stats of fraudulent description:')\n",
    "descriptive_stats(token_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive Stats of non fraudulent text\n",
    "\n",
    "\n",
    "nonfraud_df = df_new[df_new['fraudulent']== 0]\n",
    "token_nonfraud = []\n",
    "for i in nonfraud_df['token']:\n",
    "    token_nonfraud.extend(i)    \n",
    "print('Descriptive Stats of Non fraudulent description:')\n",
    "descriptive_stats(token_nonfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word clouds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create wordcloud:\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_freq\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "def count_words(df, column='token', preprocess=None, min_freq=2):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "        \n",
    "   # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "#creating word cloud for both real and fake job posting text \n",
    "\n",
    "#fake posting \n",
    "plt.figure(figsize=(8,4))\n",
    "fraud_wd= count_words(df_new[df_new['fraudulent']== 1])\n",
    "wordcloud(fraud_wd['freq'], max_words= 50)\n",
    "plt.title(\"Fraudulent Text\", size = 18)\n",
    "\n",
    "#real posting \n",
    "plt.figure(figsize=(8,4))\n",
    "nonfraud_wd= count_words(df_new[df_new['fraudulent']== 0])\n",
    "wordcloud(nonfraud_wd['freq'], max_words= 50)\n",
    "plt.title(\"Non Fraudulent Text\", size = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling techniques\n",
    "\n",
    "We have class imbalance problem.Therefore we will be comparing the model performances of original distribution with both under sampling and over sampling. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced  Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_new.drop(['fraudulent','text', 'token'], axis=1)\n",
    "y=df_new['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featuree Engineering \n",
    "\n",
    "1) BoW\n",
    "\n",
    "2) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words_list = list(stopwords.words('english'))\n",
    "\n",
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words='english', min_df=5, max_df=0.7)\n",
    "\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(X['clean_text'])\n",
    "print(tfidf_text_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words_list = list(stopwords.words('english'))\n",
    "\n",
    "count_text_vectorizer = CountVectorizer(stop_words=stop_words_list, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(X['clean_text'])\n",
    "print(count_text_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(tfidf_text_vectors,y, test_size=0.20,random_state=0,stratify=y)\n",
    "\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(count_text_vectors,y, test_size=0.20,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13611\n",
       "1      693\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13611\n",
       "1      693\n",
       "Name: fraudulent, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bow.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving clean data on local machine  \n",
    "df_new.to_csv(r'C:\\Users\\ADMIN\\Documents\\Jupyter\\Fake Job Postings\\clean_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
